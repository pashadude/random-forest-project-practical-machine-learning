library (caret)
library(ggplot2)
library(psych)
training_data <- read.csv("pml-training.csv", header=T, row.names=1, na.strings = c("NA", "","#DIV/0!"))
testing_data <- read.csv("pml-testing.csv", header=T, row.names=1, na.strings = c("NA", "","#DIV/0!"))
#lets get rid of NA's
training_data <-training_data[,colSums(is.na(training_data)) == 0]
testing_data <-testing_data[,colSums(is.na(testing_data)) == 0]
19200/19622
training_data <- training_data[-(1:6)]
testing_data <- testing_data[-(1:6)]
View(training_data)
View(training_data)
inTrain<-createDataPartition(training_data$classe, p=3/4, list=FALSE)
training<-training_data[inTrain,]
testing<-training_data[-inTrain,]
library(caret)
library(psych)
library(ggplot2)
training_data <- read.csv("pml-training.csv", header=T, row.names=1)
testing_data <- read.csv("pml-testing.csv", header=T, row.names=1)
#lets look into the data
summary(training_data)
describe(training_data)
str(training_data)
training_data <- read.csv("pml-training.csv", header=T, row.names=1, na.strings = c("NA", "","#DIV/0!"))
testing_data <- read.csv("pml-testing.csv", header=T, row.names=1, na.strings = c("NA", "","#DIV/0!"))
#lets get rid of columns with NA's (NA's form ~ 98% of values in columns where they occure)
training_data <-training_data[,colSums(is.na(training_data)) == 0]
testing_data <-testing_data[,colSums(is.nas(testing_data)) == 0]
testing_data <-testing_data[,colSums(is.nas(testing_data)) == 0]
testing_data <- read.csv("pml-testing.csv", header=T, row.names=1, na.strings = c("NA", "","#DIV/0!"))
testing_data <-testing_data[,colSums(is.nas(testing_data)) == 0]
library(caret)
library(psych)
library(ggplot2)
library(descr)
testing_data <-testing_data[,colSums(is.na(testing_data)) == 0]
training_data <- training_data[-(1:6)]
testing_data <- testing_data[-(1:6)]
inTrain<-createDataPartition(training_data$classe, p=3/4, list=FALSE)
training<-training_data[inTrain,]
validating<-training_data[-inTrain,]
CorMx<-abs(cor(training[,-53]))
diag(CorMx)<-0
ViolatingCor<-which(CorMx>0.8,arr.ind=Ts)
ViolatingCor<-which(CorMx>0.8,arr.ind=T)
View(ViolatingCor)
View(ViolatingCor)
View(CorMx)
VC<-CorMx[CorMx< 0, ]
VC<-CorMx[CorMx[] < 0.8, ]
VC<-CorMx[CorMx[,1:52] < 0.8, ]
corrplot(CorMx, method = "number", tl.cex = 0.8)
library(caret)
library(psych)
library(ggplot2)
library(descr)
library(corrplot)
CorMx<-abs(cor(training[,-53]))
diag(CorMx)<-0
corrplot(CorMx, method = "number", tl.cex = 0.8)
install.packages("corrplot")
library(corrplot)
CorMx<-abs(cor(training[,-53]))
diag(CorMx)<-0
corrplot(CorMx, method = "number", tl.cex = 0.8)
CorMx<-abs(cor(training[,-53]))
diag(CorMx)<-0
corrplot(CorMx, method = "color", tl.cex = 0.8)
CorMx<-abs(cor(training[,-53]))
diag(CorMx)<-0
corrplot(CorMx, method = "pearson", tl.cex = 0.8)
corrplot(CorMx, method = "spear", tl.cex = 0.8)
corrplot(CorMx, method = "spearman", tl.cex = 0.8)
corrplot(CorMx, method = "number", tl.cex = 0.8)
corrplot(CorMx, method = "color", tl.cex = 0.8)
corrplot(CorMx, method = "color", tl.cex = 0.8)
CorMx<-abs(cor(training[,-53]))
corrplot(CorMx, method = "color", tl.cex = 0.8)
View(training)
modelFit <- train(training$classe ~ ., method = "rf", preProcess = "pca",
data = training, trControl = trainControl( method = "repeatedcv",
number=5,
repeats=5,
preProcOptions = list(thresh = 0.99)))
preProc <- preProcess(training[, -53], method = "pca", thresh = 0.99)
library(caret)
library(psych)
library(ggplot2)
library(descr)
library(randomForest)
library(corrplot)
training_data <- read.csv("pml-training.csv", header=T, row.names=1)
testing_data <- read.csv("pml-testing.csv", header=T, row.names=1)
#lets look into the data
summary(training_data)
describe(training_data)
sapply(training_data, class)
#a lot of columns contain large share of blank data and #DIV/0!, lets turn em into NA
training_data <- read.csv("pml-training.csv", header=T, row.names=1, na.strings = c("NA", "","#DIV/0!"))
testing_data <- read.csv("pml-testing.csv", header=T, row.names=1, na.strings = c("NA", "","#DIV/0!"))
#lets get rid of columns with NA's (NA's form ~ 98% of values in columns where they occure)
training_data <-training_data[,colSums(is.na(training_data)) == 0]
testing_data <-testing_data[,colSums(is.na(testing_data)) == 0]
testing_data <-testing_data[,colSums(is.na(testing_data)) == 0]
#lets remove analysis-meaningless columns like timestamp, username, window etc.
training_data <- training_data[-(1:6)]
testing_data <- testing_data[-(1:6)]
#Now lets split the training dataset foe actual training and validation purposess
inTrain<-createDataPartition(training_data$classe, p=3/4, list=FALSE)
training<-training_data[inTrain,]
validating<-training_data[-inTrain,]
#Now I will check the correlation among the variables
CorMx<-abs(cor(training[,-53]))
corrplot(CorMx, method = "color", tl.cex = 0.8)
#image 1
#the graph shows strong corr, specifically among in belt, accel_arm/magnet_arm,gyros and dumbbell variables groups
#lets move to random forest (which takes pca analysis and repeated cross-validation)
preProc <- preProcess(training[, -53], method = "pca", thresh = 0.99)
trainingPC <- predict(preProc, training[, -53])
validatingPC <- predict(preProc, validating[, -53])
modelFit <- train(training$classe ~ .,
method = "rf",
data = trainingPC,
trControl = trainControl(method = "repeatedcv", number=5, repeats=5))
library(foreach)
library(doParallel)
install.packages("doParallel")
library(doParallel)
registerDoParallel()
modelFit <-foreach(ntree=rep(150, 4), .combine=randomForest::combine) %dopar% randomForest(trainingPC[-ncol(trainingPC)], trainingPC$classe, ntree=ntree)
C1 <- confusionMatrix(validating$classe, predict(modelFit, validatingPC))
modelFit <-foreach(ntree=rep(150, 2), .combine=randomForest::combine) %dopar% randomForest(trainingPC[-ncol(trainingPC)], trainingPC$classe, ntree=ntree)
modelFit <-foreach(ntree=rep(150, 4), .combine=randomForest::combine) %dopar% randomForest(trainingPC[-ncol(trainingPC)], trainingPC$classe, ntree=ntree)
set.seed(3433)
modelFit <- train(training$classe ~ .,
method = "rf",
data = trainingPC,
trControl = trainControl(method = "repeatedcv", number=5, repeats=5))
